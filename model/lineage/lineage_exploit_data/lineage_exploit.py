from collections import defaultdict, deque
import os
import sys
import time
import pandas as pd
import numpy as np
from pathlib import Path
sys.path.append(str(Path(os.path.abspath(__file__)).parents[3]))
from logger_module import setup_logger_global
from model.lineage.utils import PreProcessingData
from model.optimize_algo import HashTable, Node, Trie
from config import (LINEAGE_SOURCE, NODE_RAW_FROM_DB,
                     LINEAGE_TARGET, NODE_PATH, 
                     NUMBER_CHARACTER_NODE ,SOURCE_NAME, TARGET_NAME)

class LineageManta(PreProcessingData):
    def __init__(self):
        """
        Initialize LineageManta with a table name and database name.

        Parameters:
            table_name (str): The name of the table from which to retrieve relationships.
            database_name (str): The name of the database containing the table.
        """
        super().__init__()
        connection_logger_name =os.path.basename(__file__)
        self.exploit_lineage_manta = setup_logger_global(connection_logger_name, connection_logger_name + '.log')

        

    def describe_table(self, df_path: pd.DataFrame, source_col: str, target_col: str) -> dict:
        """
        Analyzes the relationships between source and target columns in a dataframe.

        Parameters:
        df_path (pandas.DataFrame): The dataframe containing source and target columns.
        source_col (str): The name of the source column in the dataframe.
        target_col (str): The name of the target column in the dataframe.

        Returns:
        dict: A dictionary containing relationship details for each unique value in the source and target columns.
            Each entry includes:
                - source_count: The count of occurrences as a source.
                - target_count: The count of occurrences as a target.
                - as_source_related: List of related values when the current value is a source.
                - as_target_related: List of related values when the current value is a target.
                - type_value: A string indicating the node type ('root', 'maxleaf', or 'branch').
                - all_values: A set of all unique values in both columns.

        Logs an error if any exception occurs during the process.
        """

        try:
            start_time = int(time.time())
            source_df = df_path[source_col]
            target_df = df_path[target_col]
            source_counts = source_df.value_counts().to_dict()
            target_counts = target_df.value_counts().to_dict()
            all_values = set(source_df.tolist() + target_df.tolist())
            relation_dict: dict = {}
            for value in all_values:
                source_relatives = target_df[source_df == value].tolist()
                target_relatives = source_df[target_df == value].tolist()

                source_count = source_counts.get(value, 0)
                target_count = target_counts.get(value, 0)

                # Lưu thông tin vào dictionary
                relation_dict[value] = {

                    "source_count": source_count,
                    "target_count": target_count,
                    "as_source_related": source_relatives,
                    "as_target_related": target_relatives
                }
            relation_dict['all_values'] = all_values
            end_time = int(time.time())
            self.exploit_lineage_manta.info(f"Time to describe table: {end_time - start_time}")
            return relation_dict
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error: {str(e)}")
    
    def get_all_value_node_not_duplicate(self, source_col, 
                                            target_col,
                                            table
                                            
                                         ):
        """
        Retrieves all unique node values from the specified source and target columns in the given table.

        Parameters:
            source_col (str): Name of the source column in the table.
            target_col (str): Name of the target column in the table.
            table (pd.DataFrame): DataFrame containing the data.
            database (str, optional): Database name. Defaults to the instance-level database_name.

        Returns:
            list: A list of unique node values from both the source and target columns.

        Logs an error if any exception occurs during the process.
        """

        try:
            all_nodes = list(set(table[source_col].tolist() + table[target_col].tolist()))
            return all_nodes
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error: {str(e)}")

    
    def redact_node_with_string(self,
                        total_nodes_df,
                        new_column_redacted = NODE_PATH, 
                        column_name_start_with = None,
                        number_node = NUMBER_CHARACTER_NODE ):
        """
        This function creates a new column in the dataframe with the name of the
        given column name and assigns each row a unique string value in the
        format of 'column_name_start_with' followed by a number padded with
        leading zeros to the given number of digits. The purpose of this function
        is to create a unique identifier for each node in the graph.

        Parameters
        ----------
        total_nodes_df : pandas.DataFrame
            The dataframe containing all the nodes in the graph.
        new_column_redacted : str, optional
            The name of the new column to be created. The default is NODE_PATH.
        column_name_start_with : str, optional
            The prefix of the string value to be assigned to each node. The
            default is None.
        number_node : int, optional
            The number of digits to pad the number with leading zeros. The
            default is NUMBER_CHARACTER_NODE.

        Returns
        -------
        pandas.DataFrame
            The dataframe with the new column added.
        """
        
        try:
            total_nodes_df[new_column_redacted] = [
                    f"{column_name_start_with}{str(i).zfill(number_node)}" for i in range(1, len(total_nodes_df) + 1)
                ]
            return total_nodes_df
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error: {str(e)}")
    
    def redact_node_with_int(self, total_nodes_df,
                        new_column_redacted = NODE_PATH
                       ):
        """
        This function creates a new column in the dataframe with the name of the
        given column name and assigns each row a unique integer value from 1 to
        the length of the dataframe. The purpose of this function is to create a
        unique identifier for each node in the graph.

        Parameters:
        total_nodes_df (pandas.DataFrame): The dataframe containing the node path
        new_column_redacted (str): The column name for the new column to be created

        Returns:
        pandas.DataFrame: The dataframe with the new column
        """
        try:
            total_nodes_df[new_column_redacted] = [
                    i for i in range(1, len(total_nodes_df) + 1)
                ]
            return total_nodes_df
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error: {str(e)}")
    
    def mapping_dict_nodepath(self, df, 
                              source_col = LINEAGE_SOURCE, 
                              target_col = LINEAGE_TARGET):
        """
        This function creates a dictionary mapping the node path to its corresponding source and target node path

        Parameters:
        df (pandas.DataFrame): The dataframe containing the node path and its corresponding source and target node path
        source_col (str): The column name for the source node path in the dataframe
        target_col (str): The column name for the target node path in the dataframe

        Returns:
        dict: A dictionary mapping the node path to its corresponding source and target node path
        """
        try:
            start_time = int(time.time())
            combo_list = df[NODE_PATH].tolist()
            dictionary = {}
            for item in combo_list:
                dictionary[item] = {}
                dictionary[item][SOURCE_NAME] = df.loc[df[NODE_PATH] == item, source_col].values[0]
                dictionary[item][TARGET_NAME] = df.loc[df[NODE_PATH] == item, target_col].values[0]
            end_tme = int(time.time())
            self.exploit_lineage_manta.info(f"Time to insert without hash table in {end_tme - start_time} seconds")
            return dictionary
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error: {str(e)}")
    
    def create_adjacency_list(self,dictionary) -> dict:
        """
        Create adjacency list from dictionary
        
        Parameters:
        dictionary (dict): Mapping node to its source and target nodes
        
        Returns:
        dict: Adjacency list
        """
        try:
            adjacency_list = defaultdict(list)
            for key, value in dictionary.items():
                if value[SOURCE_NAME] not in adjacency_list:
                    adjacency_list[value[SOURCE_NAME]] = []
                if value[TARGET_NAME] not in adjacency_list:
                    adjacency_list[value[TARGET_NAME]] = []
                adjacency_list[value[SOURCE_NAME]].append({key:value[TARGET_NAME]})
                adjacency_list[value[TARGET_NAME]].append({key:value[SOURCE_NAME]})
            return adjacency_list
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error: {str(e)}")
    
    def process_lineage(self, combo_list_copy, dictionary, adjacency_list):
        """
        Process lineage data thành đồ thị tối ưu bằng HashTable.

        Parameters:
        - combo_list_copy (list): Danh sách node ID
        - dictionary (HashTable): Mapping node với source và target
        - adjacency_list (HashTable): Danh sách kề

        Returns:
        - list of lists: Danh sách đường đi đã được lọc
        """
        try:
            def remove_subsets(paths):
                """
                Removes paths that are subsets of other paths from a list of paths.

                Parameters:
                paths (list of lists): A list of paths, where each path is represented as a list of nodes.

                Returns:
                list of lists: A filtered list of paths with subsets removed.
                """
                # Sắp xếp các đường đi theo độ dài
                paths.sort(key=len)
                filtered_paths = []

                for path in paths:
                    # Chuyển đổi đường đi thành tập hợp để kiểm tra subset
                    path_set = set(path)
                    # Kiểm tra xem có đường đi nào đã được thêm vào filtered_paths mà path là subset của nó không
                    if not any(path_set < set(existing_path) for existing_path in filtered_paths):
                        filtered_paths.append(path)

                return filtered_paths

            start_time = time.time()
            graph = []
            remaining_nodes = set(combo_list_copy)  # Dùng set để kiểm tra nhanh hơn
            queue = deque()
            valid_neighbors = HashTable(len(dictionary) * 2)  # Dự phòng tránh collision
            for node_id, node_data in dictionary.items():
                target_path = node_data[TARGET_NAME]
                try:
                    neighbors = adjacency_list.get(target_path, [])
                except Exception as e:
                    self.exploit_lineage_manta.error(f"Error: get()  {str(e)}")
                valid_neighbors.insert(node_id, {next(iter(neighbor)) for neighbor in neighbors})
            # Dùng đồ thị tối ưu bằng HashTable
            while remaining_nodes:
                root_id = min(remaining_nodes)
                if root_id not in dictionary:
                    self.exploit_lineage_manta.error(f"Root ID {root_id} not found in dictionary")
                    continue
                current_path = [(0, str(root_id), None)]
                graph.append(current_path)
                remaining_nodes.remove(root_id)
                queue = [(root_id, current_path)]
                step = 1

                while queue:
                    next_queue = []
                    for node_id, path in queue:
                        if node_id not in dictionary:
                            self.exploit_lineage_manta.error(f"Node ID {node_id} not found in dictionary")
                            continue
                        target_path = dictionary[node_id][TARGET_NAME]
                        neighbors = adjacency_list.get(target_path, [])
                        
                        for neighbor in neighbors:
                            neighbor_id = next(iter(neighbor))
                            if neighbor_id not in dictionary:
                                self.exploit_lineage_manta.error(f"Neighbor ID {neighbor_id} not found in dictionary")
                                continue
                            if dictionary[neighbor_id][SOURCE_NAME] != target_path:
                                continue
                            if neighbor_id in remaining_nodes:
                                next_path = path.copy() 
                                next_path.append((step, node_id, neighbor_id))
                                graph.append(next_path)
                                next_queue.append((neighbor_id, next_path))
                                remaining_nodes.remove(neighbor_id)
                    queue = next_queue
                    step += 1
                end_time = time.time()
                if (int(end_time) - int(start_time)) > 120:
                    self.exploit_lineage_manta.error(f"Time limit exceeded. Aborting lineage construction. Time elapsed: {int(end_time) - int(start_time)} seconds. Time limit: 120 seconds")
                    break
            filtered_paths = remove_subsets(graph)
            return filtered_paths
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in lineage_manta: {e}")

        
    def create_full_flow_from_graph(self,graph):
        """
        Creates a dictionary of full flow from a list of lineage paths.

        Parameters:
        graph (list of lists): A list of lineage paths, where each path is represented as a list of nodes.

        Returns:
        dict: A dictionary of full flow, where each key is a source node ID and the value is a list of lists of node IDs representing full flow from the source node to all target nodes.
        """
        try:
            full_flow_dict = {}
            for path in graph: # Iterate over each lineage path
                key = path[0][1]
                values = []
                if len(path) >=2:
                    for item in path[1:]:
                        if item[1] not in values:
                            values.append(item[1])
                        if item[-1] not in values:
                            values.append(item[-1])       
                else:
                    values.append(path[0][1])
                if key not in full_flow_dict:
                    full_flow_dict[key] = []
                full_flow_dict[key].append(values)
            return full_flow_dict
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in create_full_flow_from_graph: {e}")
            
    def create_dataframe_from_graph(self, graph, columns_name, character_split, sort_by = None):
        """
        Creates a Pandas DataFrame from a list of lineage paths.

        Parameters:
        graph (list of lists): A list of lineage paths, where each path is represented as a list of nodes.
        columns_name (list of strings): A list of column names for the DataFrame to be created. The length of the list must be 4.
        character_split (str): The character to be used to split the flow string in the DataFrame.
        sort_by (list of strings, optional): A list of column names to sort the DataFrame by. Defaults to None.

        Returns:
        pd.DataFrame: A DataFrame with the specified columns and data from the graph.
        """
        try:
            full_flow_dict = self.create_full_flow_from_graph(graph)
            data = []
            for key, value in full_flow_dict.items():
                root_id = key
                for item_list in value:  # Iterate over each item list in the value:
                    flow = character_split.join(map(str, item_list))
                    for  index, node in enumerate(item_list):  # Iterate over each node in the item list
                        data.append([root_id, index, flow, node])

            df_graph = pd.DataFrame(data, columns=columns_name)
            df_graph = df_graph.drop_duplicates(subset=columns_name)
            if sort_by is not None:
                df_graph = df_graph.sort_values(sort_by)
            return df_graph
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in create_dataframe_from_graph: {e}")

    def update_dataframe_with_dictionary(self, df, dictionary, character_split, node_name, flow_name, flow_implement_raw):
        """
        Updates a Pandas DataFrame with values from a dictionary.

        Parameters:
        df (pd.DataFrame): The DataFrame to be updated.
        dictionary (dict): A dictionary containing the values to be used for updating the DataFrame.
        character_split (str): The character to be used to split the flow string in the DataFrame.
        node_name (str): The column name for the node in the DataFrame.
        flow_name (str): The column name for the flow in the DataFrame.
        flow_implement_raw (str): The column name for the flow implementation raw in the DataFrame.

        Returns:
        pd.DataFrame: The updated DataFrame.
        """
        try:
            start_time = int(time.time())
            for index, row in df.iterrows():
                item = int(row[node_name])
                if item in dictionary:
                    df.at[index, LINEAGE_SOURCE] = dictionary[item][SOURCE_NAME]
                    df.at[index, LINEAGE_TARGET] = dictionary[item][TARGET_NAME]

                # Process the flow
                flow_value = row[flow_name]
                node_raw_list = set()  
                if character_split in flow_value:
                    node_list = flow_value.split(character_split)

                    for node in node_list:
                        node = int(node)
                        if node in dictionary:  # Check if node exists in the dictionary
                            node_raw_source = dictionary[node][SOURCE_NAME]
                            node_raw_target = dictionary[node][TARGET_NAME]
                            node_raw_list.add(node_raw_source)
                            node_raw_list.add(node_raw_target)
                else:
                    flow_value = int(flow_value)
                    if flow_value in dictionary:
                        
                        node_raw_source = dictionary[flow_value][SOURCE_NAME]
                        node_raw_target = dictionary[flow_value][TARGET_NAME]
                        node_raw_list.add(node_raw_source)
                        node_raw_list.add(node_raw_target)

                df.at[index, flow_implement_raw] = character_split.join(node_raw_list)

            end_time = int(time.time())
            self.exploit_lineage_manta.info(f"Time taken to update the DataFrame: {end_time - start_time} seconds")
            return df
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in update_dataframe_with_dictionary: {e}")
            return df 

    def unpivoted_dataframe(self, df, id_vars, value_vars, Raw_Node_column_name):
        
        """
        Transforms a DataFrame to have a more suitable format for further processing.

        Parameters:
        df (pandas.DataFrame): The DataFrame to be transformed.
        id_vars (list of strings): The column names to be used as id variables.
        value_vars (list of strings): The column names to be used as value variables.
        Raw_Node_column_name (str): The name for the column containing the raw node values.

        Returns:
        pd.DataFrame: The transformed DataFrame.
        """
        try:

            df_transformed = pd.melt(df, id_vars=id_vars, 
                                    value_vars=value_vars, 
                                    var_name='Type', value_name=Raw_Node_column_name)
            df_transformed.drop(columns=['Type'], inplace=True)
            return df_transformed
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in unpivoted_dataframe: {e}")
    

    def is_sublist(self,small, big):
        
        """
        Checks if a list is a sublist of another list.

        Parameters:
        small (list): The list to be checked if it is a sublist.
        big (list): The list to be checked against.

        Returns:
        bool: True if small is a sublist of big, False otherwise.
        """
        try:
            n = len(small)
            for window in (big[i:i + n] for i in range(len(big) - n + 1)):
                if window == small:
                    return True
            return False
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in is_sublist: {e}")

    def remove_subsets_trie(self, paths):
        """ Xóa bỏ các đường đi là tập con bằng Trie """
        paths.sort(key=len, reverse=True)  # Sắp xếp theo độ dài giảm dần
        trie = Trie()
        unique_paths = []
        
        for path in paths:
            path_tuple = tuple(path)  # Chuyển thành tuple để dễ so sánh
            if not trie.is_superset(path_tuple):  # Nếu chưa có đường đi lớn hơn, giữ lại
                trie.insert(path_tuple)
                unique_paths.append(path)
        
        return unique_paths
    
    def filter_object_dict(self, df, source_col, target_col, source_object_type='SourceObjectType', target_object_type='TargetObjectType'):
        """
        Filters a DataFrame to only include rows where the source and target nodes are not already in a dictionary mapping nodes to their object types.

        Parameters:
        df (pandas.DataFrame): The DataFrame to be filtered.
        source_col (str): The column name for the source node.
        target_col (str): The column name for the target node.
        source_object_type (str, optional): The column name for the source object type. Defaults to 'SourceObjectType'.
        target_object_type (str, optional): The column name for the target object type. Defaults to 'TargetObjectType'.
        """
        try:
            object_node_dict = {}
            for index, (node1, node2) in enumerate(zip(df[source_col], df[target_col])):
                node1_object_type = df.at[index, source_object_type]
                node2_object_type = df.at[index, target_object_type]
                if node1 not in object_node_dict:
                    object_node_dict[node1] = node1_object_type
                if node2 not in object_node_dict:
                    object_node_dict[node2] = node2_object_type
            return object_node_dict
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in filter_object_dict: {e}")

    def filter_table_from_object_type(self, table_filter, column_filter, filter_object_type_list, object_node_dict, value_object_type_name):
        """
        Filters a DataFrame to include only rows where the object type in a specified column
        matches any type in a given list of object types.

        Parameters:
        table_filter (pandas.DataFrame): The DataFrame to be filtered.
        column_filter (str): The column name in the DataFrame to check for object types.
        filter_object_type_list (list): A list of object types to filter by.
        object_node_dict (dict): A dictionary mapping values from the column_filter to their object types.

        Returns:
        pandas.DataFrame: A new DataFrame with filtered rows and an additional column 'ValueObjectType'
        indicating the type of each object.
        """
        try:
            filtered_rows = []  # List to collect filtered rows

            for _, row in table_filter.iterrows():
                # Check if the value in the specified column exists in the object_node_dict
                if row[column_filter] in object_node_dict:
                    # Check if any of the object types in filter_object_type_list match the object's type
                    matching_object_types = [obj_type for obj_type in filter_object_type_list if obj_type in object_node_dict[row[column_filter]]]
                    if matching_object_types:
                        # Add the row to the filtered_rows list and include the matching object type
                        row[value_object_type_name] = object_node_dict[row[column_filter]]
                        filtered_rows.append(row)
            # Create a new DataFrame from the filtered rows
            filtered_table = pd.DataFrame(filtered_rows, columns=table_filter.columns.tolist() + [value_object_type_name])
            return filtered_table.reset_index(drop=True)
        
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in filter_table_from_object_type: {e}")
    
    def extract_components(self,
        table, 
        column_extract, 
        character_split='.', 
        column_name_extracted_list=[
            {'source_database_type': 0},
            {'source_database_name': 1},
            {'schema': 2}
        ]
        ):
        """
        Extracts specific components from a column in a DataFrame based on predefined indices.

        Parameters:
            table (pd.DataFrame): The input DataFrame.
            column_extract (str): The column from which components will be extracted.
            character_split (str, optional): The character used to split the string. Defaults to '.'.
            column_name_extracted_list (list, optional): A list of dictionaries mapping column names to index positions
                                                        in the split parts. Defaults to common database structure.

        Returns:
            pd.DataFrame: The updated DataFrame with extracted components added as new columns.
        """
            # Iterate over each row in the DataFrame
        for index, row in table.iterrows():
            # Split the target column by the given character
            parts = row[column_extract].split(character_split)

            # Extract components and assign them to new columns
            for item in column_name_extracted_list:
                column_name = list(item.keys())[0]
                index_position = list(item.values())[0]
                
                # Safely handle missing or insufficient parts
                table.at[index, column_name] = parts[index_position] if len(parts) > abs(index_position) else None

        return table

class LineageMantaOptimize(LineageManta):
    def __init__(self):
        super().__init__()  
        self.logger_lineage_manta_optimize = setup_logger_global(os.path.basename(__file__), os.path.basename(__file__) + '.log')

    def process_lineage_op(self, combo_list_copy, dictionary, adjacency_list):
        """
        Process lineage data thành đồ thị tối ưu bằng HashTable.

        Parameters:
        - combo_list_copy (list): Danh sách node ID
        - dictionary (HashTable): Mapping node với source và target
        - adjacency_list (HashTable): Danh sách kề

        Returns:
        - list of lists: Danh sách đường đi đã được lọc
        """
        try:                        
            start_time = time.time()
            graph = []
            remaining_nodes = set(combo_list_copy) 
            queue = deque()
            valid_neighbors = HashTable(len(dictionary) * 2) 
            for node_id, node_data in dictionary.items():
                target_path = node_data[TARGET_NAME]
                try:
                    neighbors = adjacency_list.get(target_path, [])
                except Exception as e:
                    self.exploit_lineage_manta.error(f"Error: get()  {str(e)}")
                valid_neighbors.insert(node_id, {next(iter(neighbor)) for neighbor in neighbors})

            while remaining_nodes:
                root_id = min(remaining_nodes)
                if root_id not in dictionary:
                    # self.exploit_lineage_manta.error(f"Root ID {root_id} not found in dictionary")
                    continue
                current_path = [(0, root_id, 0)]
                graph.append(current_path)
                remaining_nodes.remove(root_id)
                queue = [(root_id, current_path)]
                step = 1
                while queue:
                    next_queue = []
                    for node_id, path in queue:
                        if node_id not in dictionary:
                            # self.exploit_lineage_manta.error(f"Node ID {node_id} not found in dictionary")
                            continue
                        target_path = dictionary[node_id][TARGET_NAME]
                        neighbors = adjacency_list.get(target_path, [])
                        
                        for neighbor in neighbors:
                            neighbor_id = next(iter(neighbor))
                            if neighbor_id not in dictionary:
                                # self.exploit_lineage_manta.error(f"Neighbor ID {neighbor_id} not found in dictionary")
                                continue
                            if dictionary[neighbor_id][SOURCE_NAME] != target_path:
                                continue
                            if neighbor_id in remaining_nodes:
                                next_path = path.copy() 
                                next_path.append((step, node_id, neighbor_id))
                                graph.append(next_path)
                                next_queue.append((neighbor_id, next_path))
                                remaining_nodes.remove(neighbor_id)
                    queue = next_queue
                    step += 1
                # self.exploit_lineage_manta.info(f"Graph size after before subset: {len(graph)}")
            # graph = remove_subsets(graph)
            filter_graph = self.remove_subsets_trie(graph)
            end_time = time.time()
            self.exploit_lineage_manta.info(f"Time limit exceeded. Aborting lineage construction. Time elapsed: {int(end_time) - int(start_time)} seconds. Time limit: 120 seconds")
            return filter_graph
        except Exception as e:
            self.exploit_lineage_manta.error(f"Error in lineage_manta: {e}")



    def describe_table_optimized(self, df_path: pd.DataFrame, source_col: str, target_col: str):
        try:
            start_time = int(time.time())

            # Tạo mapping trước thay vì filter từng dòng
            source_map = df_path.groupby(source_col)[target_col].apply(list).to_dict()
            target_map = df_path.groupby(target_col)[source_col].apply(list).to_dict()

            all_values = set(source_map.keys()).union(set(target_map.keys()))

            # Ước lượng kích thước hash table
            estimated_size = 2 * len(all_values)
            table = HashTable(estimated_size)  # Khởi tạo HashTable với kích thước phù hợp

            for value in all_values:
                node_data = {
                    "source_count": len(source_map.get(value, [])),
                    "target_count": len(target_map.get(value, [])),
                    "as_source_related": source_map.get(value, []),
                    "as_target_related": target_map.get(value, [])
                }
                table.insert(value, node_data)  # Lưu vào hash table

            table.insert("all_values", list(all_values))  # Lưu danh sách tất cả giá trị
            end_time = int(time.time())
            self.logger_lineage_manta_optimize.info(f"Optimized table described in {end_time - start_time} seconds")

            return table  # Trả về HashTable thay vì dictionary

        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error: {str(e)}")
            return None

    def mapping_dict_nodepath_optimize(self, df, source_col = LINEAGE_SOURCE, 
                              target_col = LINEAGE_TARGET):
        """
        Tạo từ điển ánh xạ đường dẫn nút đến đường dẫn nút nguồn và đích tương ứng.
        """
        try:
            # Ước lượng kích thước bảng hash dựa trên số lượng dòng của dataframe
            start_time = int(time.time())
            table_size = self.estimate_table_size(df=df)
            hash_table = HashTable(table_size)

            # Thêm dữ liệu vào hash table
            for _, row in df.iterrows():
                
                node_path = row[NODE_PATH]
                source_name = row[source_col]
                target_name = row[target_col]
                hash_table.insert(node_path, {SOURCE_NAME: source_name, TARGET_NAME: target_name})
                
            # Chuyển hash table sang dictionary
            dictionary = {key: hash_table.get(key) for key in df[NODE_PATH]}
            end_time = int(time.time())
                
            self.logger_lineage_manta_optimize.info(f"Time to insert a row into hash table optimize in {end_time - start_time} seconds")

            return dictionary
        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error: {str(e)}")

    def create_adjacency_list_optimized(self, dictionary):
        """
        Tạo danh sách kề từ bảng băm, tối ưu hiệu suất.
        """
        try:
            start_time = int(time.time())

            # Dùng HashTable thay vì dictionary thường
            table_size = len(dictionary) * 2  
            adjacency_list = HashTable(table_size)

            for key, value in dictionary.items():
                source = value[SOURCE_NAME]
                target = value[TARGET_NAME]
                # self.logger_lineage_manta_optimize.info(f"Sources: {source}, Target: {target}")

                # Lấy dữ liệu hiện tại từ HashTable, nếu không có thì gán []
                source_neighbors = adjacency_list.get(source) or []
                target_neighbors = adjacency_list.get(target) or []
                
                
                # Thêm quan hệ vào danh sách kề
                source_neighbors.append({key: target})
                target_neighbors.append({key: source})
                # self.logger_lineage_manta_optimize.info(f"Source_neighbors: {source_neighbors}, Target_neighbors: {target_neighbors}")

                # Cập nhật vào HashTable
                adjacency_list.insert(source, source_neighbors)
                adjacency_list.insert(target, target_neighbors)
                # self.logger_lineage_manta_optimize.info(f"adjacency_list: {adjacency_list}")

            end_time = int(time.time())
            self.logger_lineage_manta_optimize.info(f"Time to build adjacency list: {end_time - start_time} seconds")

            # Trả về dictionary nếu cần
            return adjacency_list
        
        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error: {str(e)}")
            return None

    def create_full_flow_from_graph_optimized(self, graph):
        try:
            start_time = int(time.time())
            full_flow_dict = defaultdict(list)
            
            for path in graph:
                key = path[0][1]
                seen = set()  # Set để kiểm tra trùng lặp nhanh
                values = []   # List để giữ thứ tự

                if len(path) >= 2:
                    for item in path[1:]:
                        if item[1] not in seen:
                            seen.add(item[1])
                            values.append(item[1])
                        if item[-1] not in seen:
                            seen.add(item[-1])
                            values.append(item[-1])
                else:
                    values.append(path[0][1])

                full_flow_dict[key].append(values)

            end_time = int(time.time())
            self.logger_lineage_manta_optimize.info(f"Time to create full flow from graph: {end_time - start_time:.5f} seconds")
            return dict(full_flow_dict)
        except Exception as e:
            self.logger_lineage_manta_optimize.info(f"Error: {str(e)}")
            return None

    
    def create_dataframe_from_graph_optimize(self, graph, columns_name, character_split, sort_by = None):
        """
        Creates a Pandas DataFrame from a list of lineage paths.

        Parameters:
        graph (list of lists): A list of lineage paths, where each path is represented as a list of nodes.
        columns_name (list of strings): A list of column names for the DataFrame to be created. The length of the list must be 4.
        character_split (str): The character to be used to split the flow string in the DataFrame.
        sort_by (list of strings, optional): A list of column names to sort the DataFrame by. Defaults to None.

        Returns:
        pd.DataFrame: A DataFrame with the specified columns and data from the graph.
        """
        try:
            start_time = int(time.time())
            full_flow_dict = self.create_full_flow_from_graph_optimized(graph)
            data = []
            for key, value in full_flow_dict.items():
                root_id = key
                for item_list in value:  # Iterate over each item list in the value:
                    flow = character_split.join(map(str, item_list))
                    for  index, node in enumerate(item_list):  # Iterate over each node in the item list
                        data.append([root_id, index, flow, node])

            df_graph = pd.DataFrame(data, columns=columns_name)
            df_graph = df_graph.drop_duplicates(subset=columns_name)
            if sort_by is not None:
                df_graph = df_graph.sort_values(sort_by)

            end_time = int(time.time())
            self.logger_lineage_manta_optimize.info(f"Time to create DataFrame from graph: {end_time - start_time} seconds")
            return df_graph
        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error in create_dataframe_from_graph: {e}")

    
    def update_dataframe_with_dictionary_optimize(self, df, dictionary, character_split, node_name, flow_name, flow_implement_raw):
        """
        Updates a Pandas DataFrame with values from a dictionary.
        Optimized to avoid `iterrows()` for better performance.
        """
        try:
            start_time = time.time()
            df[LINEAGE_SOURCE] = df[node_name].map(lambda x: dictionary.get(x, {}).get(SOURCE_NAME, ''))
            df[LINEAGE_TARGET] = df[node_name].map(lambda x: dictionary.get(x, {}).get(TARGET_NAME, ''))
            def process_flow(flow_value):
                nodes = str(flow_value).split(character_split) if character_split in str(flow_value) else [flow_value]
                node_raw_list = {dictionary.get(int(node), {}).get(SOURCE_NAME, '') for node in nodes}
                node_raw_list.update({dictionary.get(int(node), {}).get(TARGET_NAME, '') for node in nodes})
                return character_split.join(filter(None, node_raw_list))  # Bỏ phần tử rỗng ''

            df[flow_implement_raw] = df[flow_name].apply(process_flow)
            end_time = time.time()
            self.logger_lineage_manta_optimize.info(f"Time taken to update DataFrame: {int(end_time) - int(start_time)} seconds")
            
            return df
        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error in update_dataframe_with_dictionary: {e}")
            return df
        
    import pandas as pd

    def filter_object_dict_optimized(self, df, source_col, target_col, source_object_type='SourceObjectType', target_object_type='TargetObjectType'):
        """
        Optimized: Uses `zip()` to construct dictionary much faster than using `.at[]` inside a loop.
        """
        try:
            object_node_dict = {}
            for node1, node2, node1_type, node2_type in zip(df[source_col], df[target_col], df[source_object_type], df[target_object_type]):
                object_node_dict.setdefault(node1, node1_type)
                object_node_dict.setdefault(node2, node2_type)

            return object_node_dict
        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error in filter_object_dict: {e}")
            return {}

    def filter_table_from_object_type_optimized(self, table_filter, column_filter, filter_object_type_list, object_node_dict, value_object_type_name):
        """
        Optimized: Uses `map()` instead of `iterrows()` for fast lookups.
        """
        try:
            table_filter[value_object_type_name] = table_filter[column_filter].map(object_node_dict)
            filtered_table = table_filter[table_filter[value_object_type_name].isin(filter_object_type_list)].copy()

            return filtered_table.reset_index(drop=True)
        except Exception as e:
            self.logger_lineage_manta_optimize.error(f"Error in filter_table_from_object_type: {e}")
            return table_filter
